{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c16d197-b287-4bf2-af0c-d1712bc0f655",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Submodule 2 Project SOLUTIONS: Predictors of Diabetes   \n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44066136-fb08-4aee-a597-f9fb559a2a76",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this project, students will analyze a dataset containing information about various factors related to diabetes. They will use Python libraries such as NumPy, Pandas, and Matplotlib/Seaborn for data wrangling and visualization, and apply statistical inference techniques to explore relationships between variables and diabetes. The goal is to identify potential causes of diabetes through single and multiple regression analysis.\n",
    "\n",
    "## Learning Objectives\n",
    "In this project, you will practice the skills obtained in this module to understand the basis for diabetes. These skills include:\n",
    "1. Working with Pandas Dataframes with NumPy skills\n",
    "2. Visualizing the datsets\n",
    "3. Performing regression and statistical analysis to assess the relationships between biological characteristics and diabetes.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You should have completed all the tutorials in Module 2 and developed some level of comfort with the tools\n",
    "\n",
    "## Getting Started\n",
    "The 5 tasks are described below. Solutions for each part are provided in a second version of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66739a3b-c65e-495f-b903-f3064ce0428e",
   "metadata": {},
   "source": [
    "# Investigating Possible Causes of Diabetes Using Data Analysis and Statistical Inference \n",
    "\n",
    "Many clinical measurements have been associated with the risk of developing diabetes. We will use your newly developed skills to assess this dataset to evaluate the efficacy of each parameter as a predictor of diabetes. The final column (\"Diabetes\") is already dummy coded with diabetes =1. Thus, simple linear regression analysis will provide a kind of measure of the fraction of disease risk associated with that factor. \n",
    "\n",
    "Of course, more than one factor may be interacting and relating. \n",
    "\n",
    "In your bioinformatics or biological/clinical work, you might expect to do similar kinds of analysis. You should find that, compared to running these analyses in Excel or some (commercial) statistical package, you will be able to rapidly and reproducibly analyze, numerically and visually, any size dataset. In the cloud, you could analyze the kinds of datasets which could be created from the Million Veteran project or UK Biobank. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc343f03-068c-4358-868b-188a77ed2751",
   "metadata": {},
   "source": [
    "These are the columns of the diabetes data table\n",
    "1. **Pregnancies** This column represents the number of pregnancies the individual has had\r\n",
    "2. **Glucose** This column represents the glucose (blood sugar) level measured in the individual, often in mg/dL\r\n",
    "3. **Diastolic** This represents the diastolic blood pressure of the individual, measured in mmHg (millimeters of mercury)\r\n",
    "4. **Triceps** This might refer to the thickness of the skinfold at the triceps (back of the upper arm), often used as a measure of body fat percentage\r\n",
    "5. **Insulin** This column represents insulin levels measured in the individual, often in ÂµU/mL (micro-units per milliliter).\r\n",
    "6. **BMI** BMI stands for Body Mass Index, a calculated value derived from an individual's weight and height (weight in kilograms divided by the square of height in meters)\r\n",
    "7. **DPF** DPF refers to a Diabetes Pedigree Function, a measure estimating diabetes heredity based on family history\r\n",
    "8. **Age** This column represents the age of the individual\r\n",
    "9. **Diabetes** This column indicates the presence or absence of diabetes, coded as 0 (absence) and 1 (presence) of diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5243d0-b454-430a-a2dd-9aa1415b40f5",
   "metadata": {},
   "source": [
    "## Task 1: Data Exploration and Cleaning\n",
    "\n",
    "**Objective** Get familiar with the dataset and ensure it is ready for analysis.\n",
    "\n",
    "1. Load the dataset (diabetes.csv) using pandas and display the first few rows.\n",
    "2. Summarize the dataset by using df.describe() to check for mean, median, and standard deviation.\n",
    "3. Identify any missing or invalid values (e.g., 0 values in BMI, Glucose, etc., where they may not make sense).\n",
    "4. Handle missing or invalid values by replacing invalid zeros in relevant columns (e.g., BMI, Glucose, Blood Pressure) with the column's mean or median.\n",
    "5. Create histograms and boxplots for each numeric column to visualize the distribution and detect potential outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51cda2f-13e1-4a2a-9834-643d83ef9a21",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\".\" + os.sep + \"Datasets\" + os.sep + \"diabetes.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing or invalid values (e.g., zeros in specific columns)\n",
    "invalid_columns = ['glucose', 'diastolic', 'bmi', 'insulin']\n",
    "for col in invalid_columns:\n",
    "    print(f\"{col} has {sum(df[col] == 0)} invalid entries\")\n",
    "\n",
    "# Replace invalid zeros with mean or median (example: replace zeros in 'insulin')\n",
    "for col in invalid_columns:\n",
    "    df[col] = df[col].replace(0, df[col].mean())\n",
    "\n",
    "# Histograms for numeric columns\n",
    "df.hist(bins=20, figsize=(15, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplots for detecting outliers\n",
    "for col in df.columns[:-1]:  # Exclude 'Diabetes'\n",
    "    sns.boxplot(data=df, x='diabetes', y=col)\n",
    "    plt.title(f\"Boxplot of {col} by Diabetes\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f9d583-b467-4a9f-af6f-1cf541ac1d50",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "There are no obvious outliers in the histograms nor the data summary.\n",
    "\n",
    "HOWEVER, almost half of the insulin entries were recorded as zero. Since our code replaces all 0 with column averages. We should be very cautious about drawing ANY conclusions about insulin effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024cfd96-1f13-4697-bb17-21816359b49e",
   "metadata": {},
   "source": [
    "## Task 2: Visualizing Relationships Between Variables\n",
    "**Objective** Explore correlations between independent variables and diabetes.\n",
    "1. Create pairplots or scatterplots (e.g., using Seaborn.pairplot) for all numeric columns against the Diabetes column.\n",
    "2. Calculate the correlation matrix using np.corrcoef or pandas.corr() and visualize it with a heatmap (e.g., using Seaborn.heatmap).\n",
    "3. Identify the top 3 variables that have the strongest correlations with the Diabetes column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a3c2c-df2d-4b23-ad1d-8f2a03f8dbdc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Pairplot to visualize relationships\n",
    "sns.pairplot(df, hue='diabetes', vars=['glucose', 'bmi', 'insulin', 'age'])\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "print(corr_matrix)\n",
    "\n",
    "# Heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac62daf-1b56-4b49-a631-43d76e34171b",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "The correlations between diabetes and the set of predictors were positive. The largest corellation coefficients were observed for glucose (0.49), bmi (0.31) and age (o.24) so we will pursue these in the regression analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d5b16e-c273-4227-920e-fab79bd385a0",
   "metadata": {},
   "source": [
    "## Task 3: Single Linear Regression Analysis\n",
    "\n",
    "**Objective** Assess the relationship between individual predictors and diabetes.\n",
    "1. Perform single linear regression using statsmodels or sklearn to predict Diabetes (as a continuous variable) based on Glucose, BMI, Insulin\n",
    "2. Interpret the results, such as\n",
    "   - Coefficients and their significance (p-values).\n",
    "   - values (goodness of fit) for each predictor.\n",
    "3. Determine which single variable is the most important in explaining diabetes risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c953a49-98e1-4a6f-8c39-92636dad8cb2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Define independent variables for single regression\n",
    "single_vars = ['glucose', 'bmi', 'age']\n",
    "Y = df['diabetes']  # Dependent variable (binary)\n",
    "\n",
    "# Perform single regressions. \n",
    "modelG = smf.ols(\"diabetes ~ glucose\", data=df).fit()\n",
    "print(\"Regression with glucose:\")\n",
    "print(modelG.summary())\n",
    "\n",
    "modelB = smf.ols(\"diabetes ~ bmi\", data=df).fit()\n",
    "print(\"Regression with BMI:\")\n",
    "print(modelB.summary())\n",
    "\n",
    "modelA = smf.ols(\"diabetes ~ age\", data=df).fit()\n",
    "print(\"Regression with age:\")\n",
    "print(modelA.summary())\n",
    "\n",
    "\n",
    "print(f'The regression coefficients: FOr glucose {modelG.params.iloc[1]:.5f}, for bmi {modelG.params.iloc[1]:.5f}, and for Age {modelA.params.iloc[1]:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e413a-f04a-4d0e-9fe6-dfb21150e76b",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "While glucose, BMI, and age were most correlated with diabetes, they had very small regression coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9723730-d471-42fb-a717-bb29623c0b5b",
   "metadata": {},
   "source": [
    "## Task 4: Multiple Linear Regression\n",
    "\n",
    "**Objective** Build a comprehensive model to predict diabetes.\n",
    "1. Perform multiple linear regression using all independent variables (Pregnancies, Glucose, Diastolic, Triceps, Insulin, BMI, DPF, and Age)\n",
    "2. Evaluate the model, finding rsquared, rsquared_adj, coefficients\n",
    "3. Check coefficients and their significance.\n",
    "4. Perform a backward elimination process by remove variables with high p-values (> 0.05) and re-run the regression to refine the model\n",
    "5. Check the models (final vs. single linear regression) using AIC to find the **best** predictors of diabetes from this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a75c3-0a1b-4d56-8861-fc90507c8ddc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Define independent variables for multiple regression\n",
    "X = df[['pregnancies', 'glucose', 'diastolic', 'triceps', 'insulin', 'bmi', 'dpf', 'age']]\n",
    "X = sm.add_constant(X)  # Add intercept\n",
    "Y = df['diabetes']\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Model summary\n",
    "print(\"Multiple Regression Model Summary\")\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876cc20c-e969-4806-bc35-8c39a08ba2d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Backward elimination: remove variables with high p-values (>0.05) iteratively\n",
    "# just a computational version of doing what you would do one step at a time. \n",
    "while True:\n",
    "    p_values = model.pvalues\n",
    "    max_p = p_values.max()\n",
    "    if max_p > 0.05:\n",
    "        excluded_var = p_values.idxmax()\n",
    "        X = X.drop(columns=[excluded_var])\n",
    "        model = sm.OLS(Y, X).fit()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"Refined Model After Backward Elimination\")\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7763e-1cb7-41ae-98d2-0e030b5823a2",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "The model with only #pregnancies, glucose, BMI, and dpf is BETTER than the model with all the factors. The AIC is lower and the rsquared is almost identical. \n",
    "\n",
    "It appears that dpf (family hereditary factors) are more substantial than predicted by the correlation matrix. Thus, we should re-run the initial single linear regression (next box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c618dd-d84b-4b3f-8ba8-d8ebb6edd076",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "modelDPF = smf.ols(\"diabetes ~ dpf\", data=df).fit()\n",
    "print(\"Regression with dpf:\")\n",
    "print(modelDPF.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ef2b6-046d-49ab-885b-dab3fee17b47",
   "metadata": {},
   "source": [
    "### Analysis part 2:\n",
    "The regression coefficient for dpf is substantially higher than any of the three factors we evaluated previously. While the relationship is strong, the rsquared is quite low (0.03) meaning that only a small fraction of the variation in diabetes (with or without) can be accounted for by this family factor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d4963f-5246-4d17-9eb0-c144918f8335",
   "metadata": {},
   "source": [
    "## Task 5 Statistical Inference and Hypothesis Testing\n",
    "\n",
    "**Objective** Draw statistical conclusions about the dataset.\n",
    "1. Perform hypothesis tests\n",
    "   - Conduct a t-test to compare the mean Glucose levels between individuals with and without diabetes.\n",
    "   - Perform ANOVA to check if there are significant differences in BMI across multiple age groups (e.g., group ages into <30, 30-50, >50).\n",
    "2. Interpret the results and assess the significance of findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe577545-849a-4fcb-ae13-fcf921e960c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, f_oneway\n",
    "\n",
    "# T-test: Compare mean Glucose levels for individuals with and without diabetes\n",
    "diabetes_present = df[df['diabetes'] == 1]['glucose']\n",
    "diabetes_absent = df[df['diabetes'] == 0]['glucose']\n",
    "t_stat, p_val = ttest_ind(diabetes_present, diabetes_absent)\n",
    "print(f\"T-test for Glucose levels: t-statistic = {t_stat:.2f}, p-value = {p_val:.4f}\")\n",
    "\n",
    "# T-test: Compare mean family factors (dpf) for individuals with and without diabetes\n",
    "diabetes_present = df[df['diabetes'] == 1]['dpf']\n",
    "diabetes_absent = df[df['diabetes'] == 0]['dpf']\n",
    "t_stat, p_val = ttest_ind(diabetes_present, diabetes_absent)\n",
    "print(f\"T-test for DPF: t-statistic = {t_stat:.2f}, p-value = {p_val:.4f}\")\n",
    "\n",
    "# ANOVA: Compare BMI across age groups (<30, 30-50, >50)\n",
    "df['Age_Group'] = pd.cut(df['age'], bins=[0, 30, 50, np.inf], labels=['<30', '30-50', '>50'])\n",
    "anova_result = f_oneway(df[df['Age_Group'] == '<30']['diabetes'],\n",
    "                        df[df['Age_Group'] == '30-50']['diabetes'],\n",
    "                        df[df['Age_Group'] == '>50']['diabetes'])\n",
    "print(f\"ANOVA for Diabetes across Age Groups: F-statistic = {anova_result.statistic:.2f}, p-value = {anova_result.pvalue:.4f}\")\n",
    "\n",
    "# Grouped boxplot for BMI by Age Group\n",
    "sns.boxplot(data=df, x='Age_Group', y='bmi', hue='diabetes')\n",
    "plt.title(\"BMI by Age Group and Diabetes Status\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7622ed1-35da-4da9-91c9-59db3d1a268b",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "Diabetes rates are higher with higher \\[glucose] and dpf. \n",
    "\n",
    "Diabetes differs with age group in this dataset. \n",
    "\n",
    "However, we can see in the graph that the BMI of young diabetics is often higher than older diabetics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83870170-da6c-4665-8964-6d42ae9edaf1",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "You have demonstrated your ability to use Python for common data science tasks using NumPy, Pandas, matplotlib, Seaborn, and Statsmodel. \n",
    "\n",
    "The final [Module](../Submodule_3_Overview.ipynb) will enable you to effectively use object oriented programming in python.  \n",
    "\n",
    "### Clean up\n",
    "In order to avoid unnecessary charges, be sure to stop your compute instance when you are done working with Jupyter notebooks for the day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
